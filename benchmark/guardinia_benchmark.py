#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GuardinIA v5.1 â€” Benchmark Definitivo
Hybrid Fraud Detection Engine | AWS Serverless

MÃ©tricas geradas:
  - Accuracy, Precision, Recall, F1-Score por classe
  - Matriz de confusÃ£o completa
  - LatÃªncia real (mÃ©dia, P50, P90, P95, P99, max)
  - Uso do Bedrock por categoria
  - Score distribution
  - Exemplos de acertos e erros reais
  - RelatÃ³rio publicÃ¡vel em JSON + TXT

EstratÃ©gia tÃ©cnica:
  Usa a rota Web System da Lambda (/webhook com {"mensagem": "..."})
  que retorna JSON estruturado com status, score, confianÃ§a e indicadores.
  Sem HMAC. Sem WhatsApp. Dados 100% reais de produÃ§Ã£o.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json
import time
import urllib.request
import urllib.error
import statistics
import os
import sys
from datetime import datetime, timezone
from collections import defaultdict
from typing import Dict, List, Optional, Tuple


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ENDPOINT = os.environ.get(
    "GUARDINIA_ENDPOINT",
    "https://ly9yvqdsta.execute-api.us-east-1.amazonaws.com/prod/webhook"
)

DATASET_PATH = os.environ.get(
    "GUARDINIA_DATASET",
    "guardinia_dataset.json"
)

# Delay entre requisiÃ§Ãµes (segundos) â€” evita throttling
REQUEST_DELAY = float(os.environ.get("REQUEST_DELAY", "0.3"))

# Timeout por requisiÃ§Ã£o
REQUEST_TIMEOUT = int(os.environ.get("REQUEST_TIMEOUT", "15"))

# Quantas mensagens testar (None = todas)
LIMIT = os.environ.get("LIMIT")
LIMIT = int(LIMIT) if LIMIT else None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAPEAMENTO DE CLASSIFICAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# score >= 120  â†’ ğŸ”´ GOLPE CONFIRMADO
# score >= 80   â†’ ğŸŸ  ALTAMENTE SUSPEITO
# score >= 50   â†’ ğŸŸ¡ SUSPEITO
# score >= 30   â†’ ğŸŸ¢ BAIXO RISCO
# score <  30   â†’ âœ… SEGURO

def status_to_label(status: str, score: int) -> str:
    """
    Converte status da Lambda â†’ GOLPE / AMBIGUA / LEGITIMA
    para comparaÃ§Ã£o com o dataset.

    Thresholds reais da Lambda (whatsapp_lambda_V5_3):
      score >= 120 â†’ ğŸ”´ GOLPE CONFIRMADO
      score >= 80  â†’ ğŸŸ  ALTAMENTE SUSPEITO
      score >= 50  â†’ ğŸŸ¡ SUSPEITO
      score >= 30  â†’ ğŸŸ¢ BAIXO RISCO
      score <  30  â†’ âœ… SEGURO
    """
    s = status.upper()
    if "GOLPE CONFIRMADO" in s:
        return "GOLPE"
    elif "ALTAMENTE SUSPEITO" in s:
        return "GOLPE"
    elif "SUSPEITO" in s:
        # ğŸŸ¡ SUSPEITO = score 50-79 â†’ zona cinzenta = AMBIGUA
        return "AMBIGUA"
    elif "BAIXO RISCO" in s:
        # score 30-49 â†’ calibrado como LEGITIMA apÃ³s anÃ¡lise do benchmark v1
        return "LEGITIMA"
    elif "SEGURO" in s:
        return "LEGITIMA"
    else:
        # Fallback por score (escala real da Lambda)
        if score >= 80:
            return "GOLPE"
        elif score >= 30:
            return "AMBIGUA"
        else:
            return "LEGITIMA"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLIENTE HTTP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze(mensagem: str) -> Tuple[Optional[dict], float, Optional[str]]:
    """
    Envia mensagem para a rota Web System da Lambda.
    Retorna: (resultado_dict, latencia_ms, erro_str)
    """
    payload = json.dumps(
        {"mensagem": mensagem},
        ensure_ascii=False
    ).encode("utf-8")

    req = urllib.request.Request(
        ENDPOINT,
        data=payload,
        headers={
            "Content-Type": "application/json; charset=utf-8",
        },
        method="POST"
    )

    start = time.perf_counter()
    try:
        with urllib.request.urlopen(req, timeout=REQUEST_TIMEOUT) as resp:
            latencia_ms = (time.perf_counter() - start) * 1000
            body = resp.read().decode("utf-8")
            data = json.loads(body)
            return data, latencia_ms, None

    except urllib.error.HTTPError as e:
        latencia_ms = (time.perf_counter() - start) * 1000
        body = e.read().decode("utf-8") if e.fp else ""
        return None, latencia_ms, f"HTTP {e.code}: {body[:200]}"

    except Exception as e:
        latencia_ms = (time.perf_counter() - start) * 1000
        return None, latencia_ms, str(e)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ‰TRICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calcular_metricas(resultados: list) -> dict:
    """Calcula todas as mÃ©tricas a partir dos resultados coletados."""

    classes = ["GOLPE", "AMBIGUA", "LEGITIMA"]
    cm = defaultdict(lambda: defaultdict(int))

    latencias = []
    bedrock_count = 0
    bedrock_by_category = defaultdict(int)
    bedrock_model_count = defaultdict(int)
    score_by_category = defaultdict(list)
    erros_http = 0
    total_custo_usd = 0.0

    acertos = []
    erros = []

    for r in resultados:
        if r["erro"]:
            erros_http += 1
            continue

        real = r["categoria_real"]
        pred = r["categoria_pred"]
        latencias.append(r["latencia_ms"])

        cm[real][pred] += 1

        if r.get("bedrock_usado"):
            bedrock_count += 1
            bedrock_by_category[real] += 1
            modelo = r.get("bedrock_modelo", "desconhecido")
            bedrock_model_count[modelo] += 1

        custo = r.get("bedrock_custo_usd") or 0
        total_custo_usd += float(custo) if custo else 0

        score_by_category[real].append(r["score"])

        if real == pred:
            acertos.append(r)
        else:
            erros.append(r)

    total_validos = len(resultados) - erros_http
    total_acertos = sum(cm[c][c] for c in classes)
    accuracy = total_acertos / total_validos if total_validos > 0 else 0

    # Precision, Recall, F1 por classe
    por_classe = {}
    for c in classes:
        tp = cm[c][c]
        fp = sum(cm[outro][c] for outro in classes if outro != c)
        fn = sum(cm[c][outro] for outro in classes if outro != c)

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1        = (2 * precision * recall / (precision + recall)
                     if (precision + recall) > 0 else 0)

        support = sum(cm[c].values())

        por_classe[c] = {
            "tp": tp, "fp": fp, "fn": fn,
            "precision": round(precision, 4),
            "recall":    round(recall, 4),
            "f1":        round(f1, 4),
            "support":   support
        }

    # Macro F1
    macro_f1 = statistics.mean(
        por_classe[c]["f1"] for c in classes
    )

    # LatÃªncia
    lat_sorted = sorted(latencias)
    n = len(lat_sorted)

    def percentil(lst, p):
        idx = max(0, int(len(lst) * p / 100) - 1)
        return lst[idx] if lst else 0

    metricas_lat = {
        "media_ms":  round(statistics.mean(latencias), 1) if latencias else 0,
        "mediana_ms": round(statistics.median(latencias), 1) if latencias else 0,
        "p90_ms":    round(percentil(lat_sorted, 90), 1),
        "p95_ms":    round(percentil(lat_sorted, 95), 1),
        "p99_ms":    round(percentil(lat_sorted, 99), 1),
        "min_ms":    round(min(latencias), 1) if latencias else 0,
        "max_ms":    round(max(latencias), 1) if latencias else 0,
        "stdev_ms":  round(statistics.stdev(latencias), 1) if len(latencias) > 1 else 0,
    }

    # Score mÃ©dio por categoria
    score_stats = {
        cat: {
            "media": round(statistics.mean(scores), 1) if scores else 0,
            "mediana": round(statistics.median(scores), 1) if scores else 0,
            "min": min(scores) if scores else 0,
            "max": max(scores) if scores else 0,
        }
        for cat, scores in score_by_category.items()
    }

    return {
        "total_testadas":      len(resultados),
        "total_validas":       total_validos,
        "total_erros_http":    erros_http,
        "total_acertos":       total_acertos,
        "accuracy":            round(accuracy, 4),
        "accuracy_pct":        round(accuracy * 100, 2),
        "macro_f1":            round(macro_f1, 4),
        "por_classe":          por_classe,
        "confusion_matrix":    {k: dict(v) for k, v in cm.items()},
        "latencia":            metricas_lat,
        "bedrock": {
            "total_acionado":  bedrock_count,
            "taxa_acionamento": round(bedrock_count / total_validos * 100, 1) if total_validos > 0 else 0,
            "por_categoria":   dict(bedrock_by_category),
            "por_modelo":      dict(bedrock_model_count),
            "custo_total_usd": round(total_custo_usd, 6),
        },
        "score_stats":         score_stats,
        "exemplos_acerto":     acertos[:5],
        "exemplos_erro":       erros[:10],
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RELATÃ“RIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def gerar_relatorio(m: dict, meta: dict) -> str:
    """Gera relatÃ³rio ASCII publicÃ¡vel."""

    divider = "â•" * 70
    thin    = "â”€" * 70

    linhas = [
        "",
        divider,
        "  GuardinIA v5.1 â€” BENCHMARK REPORT",
        f"  Data: {meta['data']}",
        f"  Endpoint: {meta['endpoint']}",
        divider,
        "",
        "  SUMÃRIO EXECUTIVO",
        thin,
        f"  Total testadas    : {m['total_testadas']:>6}",
        f"  RequisiÃ§Ãµes OK    : {m['total_validas']:>6}",
        f"  Erros HTTP        : {m['total_erros_http']:>6}",
        f"  Taxa sucesso HTTP : {(m['total_validas']/m['total_testadas']*100):.1f}%",
        "",
        f"  âœ… Accuracy geral : {m['accuracy_pct']:.2f}%",
        f"  ğŸ“Š Macro F1-Score  : {m['macro_f1']:.4f}",
        "",
    ]

    # MÃ©tricas por classe
    linhas += [
        "  MÃ‰TRICAS POR CLASSE",
        thin,
        f"  {'Classe':<12} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Support':>10}",
        f"  {'-'*12} {'-'*10} {'-'*10} {'-'*10} {'-'*10}",
    ]
    for cls, v in m["por_classe"].items():
        linhas.append(
            f"  {cls:<12} {v['precision']:>10.4f} {v['recall']:>10.4f} {v['f1']:>10.4f} {v['support']:>10}"
        )
    linhas.append("")

    # Matriz de confusÃ£o
    classes = ["GOLPE", "AMBIGUA", "LEGITIMA"]
    cm = m["confusion_matrix"]
    linhas += [
        "  MATRIZ DE CONFUSÃƒO",
        "  (linhas = real, colunas = predito)",
        thin,
        f"  {'':15} {'GOLPE':>10} {'AMBIGUA':>10} {'LEGITIMA':>10}",
        f"  {'-'*15} {'-'*10} {'-'*10} {'-'*10}",
    ]
    for real in classes:
        row = cm.get(real, {})
        linhas.append(
            f"  {real:<15} {row.get('GOLPE',0):>10} {row.get('AMBIGUA',0):>10} {row.get('LEGITIMA',0):>10}"
        )
    linhas.append("")

    # LatÃªncia
    lat = m["latencia"]
    linhas += [
        "  LATÃŠNCIA (produÃ§Ã£o real)",
        thin,
        f"  MÃ©dia   : {lat['media_ms']:>7.1f} ms",
        f"  Mediana : {lat['mediana_ms']:>7.1f} ms",
        f"  P90     : {lat['p90_ms']:>7.1f} ms",
        f"  P95     : {lat['p95_ms']:>7.1f} ms",
        f"  P99     : {lat['p99_ms']:>7.1f} ms",
        f"  Min     : {lat['min_ms']:>7.1f} ms",
        f"  Max     : {lat['max_ms']:>7.1f} ms",
        f"  StdDev  : {lat['stdev_ms']:>7.1f} ms",
        "",
    ]

    # Bedrock
    bk = m["bedrock"]
    linhas += [
        "  BEDROCK (Escalonamento Cognitivo)",
        thin,
        f"  Acionamentos    : {bk['total_acionado']}",
        f"  Taxa            : {bk['taxa_acionamento']:.1f}%",
        f"  Custo estimado  : USD {bk['custo_total_usd']:.6f}",
    ]
    if bk["por_categoria"]:
        linhas.append("  Por categoria:")
        for cat, cnt in bk["por_categoria"].items():
            linhas.append(f"    â€¢ {cat}: {cnt}")
    if bk["por_modelo"]:
        linhas.append("  Por modelo:")
        for mdl, cnt in bk["por_modelo"].items():
            linhas.append(f"    â€¢ {mdl}: {cnt}")
    linhas.append("")

    # Score stats
    linhas += [
        "  SCORE MÃ‰DIO POR CATEGORIA",
        thin,
    ]
    for cat, s in m["score_stats"].items():
        linhas.append(
            f"  {cat:<12}: mÃ©dia={s['media']:.1f}  mediana={s['mediana']:.1f}  [{s['min']}â€“{s['max']}]"
        )
    linhas.append("")

    # Exemplos de erros
    if m["exemplos_erro"]:
        linhas += [
            "  EXEMPLOS DE CLASSIFICAÃ‡ÃƒO INCORRETA",
            thin,
        ]
        for i, ex in enumerate(m["exemplos_erro"][:6], 1):
            msg_preview = ex["mensagem"][:80].replace("\n", " ")
            linhas += [
                f"  [{i}] Real: {ex['categoria_real']} â†’ Predito: {ex['categoria_pred']}",
                f"      Score: {ex['score']} | Status: {ex['status']}",
                f"      \"{msg_preview}...\"",
                "",
            ]

    linhas += [
        divider,
        "  GuardinIA â€” Hybrid Fraud Detection Engine",
        "  AWS Lambda Â· API Gateway Â· DynamoDB Â· Bedrock Â· Serverless",
        divider,
        "",
    ]

    return "\n".join(linhas)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BARRA DE PROGRESSO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def progress_bar(current: int, total: int, width: int = 40) -> str:
    pct  = current / total
    done = int(width * pct)
    bar  = "â–ˆ" * done + "â–‘" * (width - done)
    return f"[{bar}] {current:>4}/{total} ({pct*100:.1f}%)"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("\n" + "â•" * 70)
    print("  GuardinIA v5.1 â€” Iniciando Benchmark")
    print("â•" * 70)
    print(f"  Endpoint : {ENDPOINT}")
    print(f"  Dataset  : {DATASET_PATH}")
    print(f"  Delay    : {REQUEST_DELAY}s entre requisiÃ§Ãµes")
    print("â•" * 70 + "\n")

    # Carrega dataset
    if not os.path.exists(DATASET_PATH):
        print(f"âŒ Dataset nÃ£o encontrado: {DATASET_PATH}")
        print("   Passe o caminho via variÃ¡vel: GUARDINIA_DATASET=caminho.json")
        sys.exit(1)

    with open(DATASET_PATH, "r", encoding="utf-8") as f:
        dataset = json.load(f)

    if LIMIT:
        dataset = dataset[:LIMIT]

    total = len(dataset)
    print(f"  ğŸ“¦ {total} mensagens carregadas\n")

    resultados = []
    inicio_total = time.time()

    for i, item in enumerate(dataset, 1):
        categoria_real = item["categoria"]
        mensagem = item["mensagem"]
        msg_preview = mensagem[:60].replace("\n", " ")

        # Progresso
        bar = progress_bar(i, total)
        print(f"\r  {bar}  {msg_preview[:30]:<30}", end="", flush=True)

        # Chamada real
        resultado, latencia_ms, erro = analyze(mensagem)

        if erro or not resultado:
            resultados.append({
                "id": item.get("id"),
                "categoria_real": categoria_real,
                "categoria_pred": "ERRO",
                "mensagem": mensagem,
                "status": None,
                "score": None,
                "latencia_ms": latencia_ms,
                "bedrock_usado": False,
                "bedrock_modelo": None,
                "bedrock_custo_usd": None,
                "erro": erro or "resposta_vazia",
            })
        else:
            status   = resultado.get("status", "")
            score    = resultado.get("score", 0) or 0
            indicadores = resultado.get("indicadores", {}) or {}

            categoria_pred = status_to_label(status, score)
            bedrock_usado  = indicadores.get("fusao_aplicada", False)
            bedrock_modelo = indicadores.get("bedrock_modelo")
            bedrock_custo  = indicadores.get("bedrock_custo_usd")

            resultados.append({
                "id": item.get("id"),
                "categoria_real": categoria_real,
                "categoria_pred": categoria_pred,
                "mensagem": mensagem,
                "status": status,
                "score": score,
                "confianca": resultado.get("confianca"),
                "motivos": resultado.get("motivos", [])[:3],
                "latencia_ms": round(latencia_ms, 2),
                "bedrock_usado": bedrock_usado,
                "bedrock_modelo": bedrock_modelo,
                "bedrock_custo_usd": bedrock_custo,
                "erro": None,
            })

        if i < total:
            time.sleep(REQUEST_DELAY)

    tempo_total_s = time.time() - inicio_total
    print(f"\n\n  âœ… ConcluÃ­do em {tempo_total_s:.1f}s\n")

    # Calcula mÃ©tricas
    metricas = calcular_metricas(resultados)

    # Metadados
    meta = {
        "data": datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC"),
        "endpoint": ENDPOINT,
        "total_mensagens": total,
        "tempo_total_segundos": round(tempo_total_s, 2),
        "versao_benchmark": "1.0.0",
    }

    # RelatÃ³rio ASCII
    relatorio_txt = gerar_relatorio(metricas, meta)
    print(relatorio_txt)

    # Salva JSON completo
    output_json = {
        "meta": meta,
        "metricas": metricas,
        "resultados_individuais": resultados,
    }

    nome_base = f"guardinia_benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    with open(f"{nome_base}.json", "w", encoding="utf-8") as f:
        json.dump(output_json, f, ensure_ascii=False, indent=2)

    with open(f"{nome_base}.txt", "w", encoding="utf-8") as f:
        f.write(relatorio_txt)

    print(f"  ğŸ’¾ JSON salvo : {nome_base}.json")
    print(f"  ğŸ“„ TXT salvo  : {nome_base}.txt\n")


if __name__ == "__main__":
    main()
